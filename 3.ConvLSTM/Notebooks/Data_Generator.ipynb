{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install import_ipynb nbformat\n",
    "\n",
    "import import_ipynb\n",
    "from Label_Utilities import build_label_dictionary\n",
    "from Layer_Utilities import anchor_boxes, IoU, get_gt_data\n",
    "from Image_Utilities import (apply_random_crop, apply_random_exposure_adjust,\n",
    "                             apply_random_intensity_rescale,\n",
    "                             apply_random_noise, apply_horizontal_flip,\n",
    "                             read_image, resize_with_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The DataGenerator class inherits from the Sequence class of Keras to ensure\n",
    "that it supports multi-processing. DataGenerator guarantees that the entire\n",
    "dataset is used in one epoch.\n",
    "\n",
    "The length of the entire epoch given a batch size is returned by the\n",
    "__len__() method. Every request for a mini-batch of data is fulfilled by\n",
    "the __getitem__() method. After every epoch, the on_epoch_end() method is\n",
    "called to shuffle the entire batch if self.shuffle is True.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Multi-threaded data generator.\n",
    "    Each thread read a batch of images and their object labels\n",
    "    \n",
    "    # Arguments:\n",
    "        args: User-defined configuration\n",
    "        dictionary (dict): Dictionary of image filenames and object labels\n",
    "        n_classes (int): Number of object classes\n",
    "        feature_shapes (tensor): Shapes of ssd head feature maps\n",
    "        n_anchors (int): Number of anchors per feature point (eg 4)\n",
    "        shufle (bool): If dataset should be shuffled before sampling\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 args,\n",
    "                 dictionary,\n",
    "                 n_classes,\n",
    "                 feature_shapes=[],\n",
    "                 n_anchors=4,\n",
    "                 horizontal_flip=0.,\n",
    "                 random_crop = 0.,\n",
    "                 random_exposure_adjust = 0,\n",
    "                 random_intensity_rescale = 0.,\n",
    "                 random_noise=0.,\n",
    "                 shuffle=True):\n",
    "        self.args = args\n",
    "        self.dictionary = dictionary\n",
    "        self.n_classes = n_classes\n",
    "        self.keys = np.array(list(self.dictionary.keys()))\n",
    "        self.input_shape = (args['height'], args['width'], args['channels'])\n",
    "        self.feature_shapes = feature_shapes\n",
    "        self.n_anchors = n_anchors\n",
    "        \n",
    "        # data augmentation\n",
    "        self.horizontal_flip = horizontal_flip\n",
    "        self.random_crop = random_crop\n",
    "        self.random_exposure_adjust = random_exposure_adjust\n",
    "        self.random_intensity_rescale = random_intensity_rescale\n",
    "        self.random_noise = random_noise\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.on_epoch_end()\n",
    "        self.get_n_boxes()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches per epoch\n",
    "        \"\"\"\n",
    "        batch_len = np.floor(len(self.dictionary) / self.args['batch_size'])\n",
    "        return int(batch_len)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Get a batch of data\"\"\"\n",
    "        start_index = index * self.args['batch_size']\n",
    "        end_index = start_index + self.args['batch_size']\n",
    "        keys = self.keys[start_index:end_index]\n",
    "        x, y = self.__data_generation(keys)\n",
    "        return x, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Shuffle after each epoch\"\"\"\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.keys)\n",
    "\n",
    "    def get_n_boxes(self):\n",
    "        \"\"\"Total number of bounding boxes\"\"\"\n",
    "        self.n_boxes = 0\n",
    "        for feature_shape in self.feature_shapes:\n",
    "            self.n_boxes += np.prod(\n",
    "                feature_shape) // 4  # // self.n_anchors ???\n",
    "        logging.info(f\"Data Generator: # boxes = {self.n_boxes}\")\n",
    "        return self.n_boxes\n",
    "\n",
    "    def __data_generation(self, keys):\n",
    "        \"\"\"Generate train data: images and\n",
    "        object detection ground truth labels\n",
    "        \n",
    "        # Arguments:\n",
    "            keys (array): Randomly sampled keys (key is image filename)\n",
    "        # Returns:\n",
    "            x (tensor): Batch images\n",
    "            y (tensor): Batch  classes, offsets and masks\n",
    "        \"\"\"\n",
    "        # train input data\n",
    "        x = np.zeros((self.args['batch_size'], *self.input_shape),\n",
    "                     dtype=np.float32)\n",
    "        # class ground truth\n",
    "        dim = (self.args['batch_size'], self.n_boxes, self.n_classes)\n",
    "        gt_class = np.zeros(dim)\n",
    "        # offsets ground truth\n",
    "        dim = (self.args['batch_size'], self.n_boxes, 4)\n",
    "        gt_offset = np.zeros(dim)\n",
    "        # masks of valid bounding boxes\n",
    "        gt_mask = np.zeros(dim)\n",
    "\n",
    "        for i, key in enumerate(keys):\n",
    "            # images are assumed to be stores in self.args['data_path']\n",
    "            # key is the image filename\n",
    "            image_path = os.path.join(self.args['data_path'], key)\n",
    "            # a label entry is made of 4-dim bounding box coords\n",
    "            # and 1-dim class label\n",
    "            labels = self.dictionary[key]\n",
    "\n",
    "            # read image and labels\n",
    "            image, labels = read_image(image_path, labels=labels)\n",
    "\n",
    "            # horizontal_flip\n",
    "            image, labels = apply_horizontal_flip(image, labels, self.horizontal_flip)\n",
    "            \n",
    "            # random_crop\n",
    "            image, labels = apply_random_crop(image, labels, self.random_crop)\n",
    "            \n",
    "            # random_intensity_rescale\n",
    "            image = apply_random_intensity_rescale(image, self.random_intensity_rescale)\n",
    "            \n",
    "            # random_exposure_adjust\n",
    "            image = apply_random_exposure_adjust(image, self.random_exposure_adjust)\n",
    "            \n",
    "            # random noise\n",
    "            image = apply_random_noise(image, self.random_noise)\n",
    "            \n",
    "            if image.shape[0:2] != self.input_shape[0:2]:\n",
    "                image, labels = resize_with_pad(image,\n",
    "                                                labels,\n",
    "                                                *self.input_shape[0:2])\n",
    "            assert (image.shape == self.input_shape)\n",
    "            \n",
    "            x[i] = image\n",
    "            # 4 bounding box coords are 1st four items of labels\n",
    "            # last item is object class label\n",
    "            labels = np.array(labels)\n",
    "            boxes = labels[:, 0:-1]\n",
    "\n",
    "            for index, feature_shape in enumerate(self.feature_shapes):\n",
    "                # generate anchor boxes\n",
    "                anchors = anchor_boxes(\n",
    "                    feature_shape,\n",
    "                    image.shape,\n",
    "                    index=index,\n",
    "                    n_layers=self.args['layers'],\n",
    "                    aspect_ratios=self.args['aspect_ratios'])\n",
    "                # each feature layer has a row of anchor boxes\n",
    "                anchors = np.reshape(anchors, [-1, 4])\n",
    "                # compute IoU of each anchor box\n",
    "                # with respect to each bounding boxes\n",
    "                iou = IoU(anchors, boxes)\n",
    "                # generate ground truth class, offset and mask\n",
    "                gt = get_gt_data(iou,\n",
    "                                 n_classes=self.n_classes,\n",
    "                                 anchors=anchors,\n",
    "                                 labels=labels,\n",
    "                                 normalize=self.args['normalize'],\n",
    "                                 threshold=self.args['threshold'])\n",
    "                gt_cls, gt_off, gt_msk = gt\n",
    "\n",
    "                if index == 0:\n",
    "                    cls = np.array(gt_cls)\n",
    "                    off = np.array(gt_off)\n",
    "                    msk = np.array(gt_msk)\n",
    "                else:\n",
    "                    cls = np.append(cls, gt_cls, axis=0)\n",
    "                    off = np.append(off, gt_off, axis=0)\n",
    "                    msk = np.append(msk, gt_msk, axis=0)\n",
    "\n",
    "            gt_class[i] = cls\n",
    "            gt_offset[i] = off\n",
    "            gt_mask[i] = msk\n",
    "        y = [gt_class, np.concatenate((gt_offset, gt_mask), axis=-1)]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from matplotlib import pyplot as plt\n",
    "    from matplotlib.patches import Rectangle\n",
    "    \n",
    "    # pip install import_ipynb nbformat\n",
    "\n",
    "    import import_ipynb  # neccessary to import a Jupyter notebook\n",
    "    from Label_Utilities import build_label_dictionary\n",
    "    from Boxes import show_boxes\n",
    "\n",
    "    args = {\n",
    "        # params execution\n",
    "        'dataset': 'voc2017',\n",
    "\n",
    "        # configuration\n",
    "        'aspect_ratios': (1., 2., 0.5, 3., 1./3.),\n",
    "        'height': 300,\n",
    "        'width': 300,\n",
    "        'channels': 3,\n",
    "        'layers': 4,\n",
    "        'normalize': False,\n",
    "        'batch_size': 1,\n",
    "        'data_path': os.path.join('datasets', 'voc2007'),\n",
    "\n",
    "        # params Non Maximum Suppresion\n",
    "        'soft_nms': False,\n",
    "        'iou_threshold': 0.3, # remove overlapping predictions with iou>threshold\n",
    "        'class_threshold': 0.8, # if max obj probability is less than theshold (def 0.8) break\n",
    "\n",
    "        # params: train\n",
    "        'train_labels': 'labels_train.csv',\n",
    "        'threshold': 0.6,\n",
    "    }\n",
    "    \n",
    "\n",
    "    # build args to data generator\n",
    "    path = os.path.join(args['data_path'], args['train_labels'])\n",
    "    dictionary, classes = build_label_dictionary(path)\n",
    "    n_anchors = len(args['aspect_ratios']) + 1\n",
    "    feature_shapes = (\n",
    "        (18, 18, 24), (9, 9, 24), (5, 5, 24), (3, 3, 24))  # el tercer campo entre 4 igual al numero de aspect+ratios +1\n",
    "    \n",
    "    assert(args['layers'] == len(feature_shapes))\n",
    "\n",
    "    data_generator = DataGenerator(args,\n",
    "                                   dictionary,\n",
    "                                   n_classes=len(classes),\n",
    "                                   feature_shapes=feature_shapes,\n",
    "                                   n_anchors=n_anchors,\n",
    "                                   random_crop = 1.0,\n",
    "                                   random_exposure_adjust=0.,\n",
    "                                   random_intensity_rescale=0.,\n",
    "                                   horizontal_flip = 0.,\n",
    "                                   random_noise = 0.,\n",
    "                                   shuffle=False)\n",
    "\n",
    "    i = 0\n",
    "    for image_batch, (class_batch, offset_batch) in data_generator:\n",
    "        j = np.random.randint(0, args['batch_size'])\n",
    "        \n",
    "        image, classes, offsets = image_batch[j], class_batch[j], offset_batch[j]\n",
    "\n",
    "        class_names, rects, _, _ = show_boxes(args,\n",
    "                                              image,\n",
    "                                              classes,\n",
    "                                              offsets,\n",
    "                                              feature_shapes,\n",
    "                                              show=True)\n",
    "\n",
    "        print(class_names, offsets.shape)\n",
    "\n",
    "\n",
    "\n",
    "        for index, feature_shape in enumerate(feature_shapes):\n",
    "            anchor = anchor_boxes(feature_shape,\n",
    "                                  image.shape,\n",
    "                                  index=index,\n",
    "                                  n_layers=args['layers'],\n",
    "                                  aspect_ratios=args['aspect_ratios'])\n",
    "            anchor = np.reshape(anchor, (-1, 4))\n",
    "            if index == 0:\n",
    "                anchors = anchor\n",
    "            else:\n",
    "                anchors = np.concatenate((anchors, anchor), axis=0)\n",
    "\n",
    "        fig, ax = plt.subplots(1)\n",
    "        ax.imshow(image)\n",
    "\n",
    "        # get all non-zero (non-background) objects\n",
    "        objects = np.argmax(classes, axis=1)\n",
    "        # non-zero indexes are not background\n",
    "        nonbg = np.nonzero(objects)[0]\n",
    "\n",
    "        for idx in nonbg:\n",
    "            # batch, row, col, box\n",
    "            anchor = anchors[idx]\n",
    "            # default anchor box format is\n",
    "            # xmin, xmax, ymin, ymax\n",
    "            w0 = anchor[1] - anchor[0]\n",
    "            h0 = anchor[3] - anchor[2]\n",
    "            x0 = anchor[0]\n",
    "            y0 = anchor[2]\n",
    "            offset = offsets[idx]\n",
    "\n",
    "\n",
    "            box = anchor + offset[0:4]\n",
    "\n",
    "            # default anchor box format is\n",
    "            # xmin, xmax, ymin, ymax\n",
    "            w1 = box[1] - box[0]\n",
    "            h1 = box[3] - box[2]\n",
    "            x1 = box[0]\n",
    "            y1 = box[2]\n",
    "\n",
    "            iou = IoU(np.expand_dims(anchors[idx], axis=0), np.expand_dims(box, axis=0))\n",
    "\n",
    "            if iou > args['threshold']:\n",
    "\n",
    "                print(\"IoU\", iou)\n",
    "                print(\"anchor:\", anchor)\n",
    "                print(\"offset: \", offset[0:4])\n",
    "                print(\"boxes\", box)\n",
    "                rect = Rectangle((x0, y0),\n",
    "                             w0,\n",
    "                             h0,\n",
    "                             linewidth=2,\n",
    "                             edgecolor='blue',\n",
    "                             facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                print(\"\\n\")\n",
    "                rect = Rectangle((x1, y1),\n",
    "                             w1,\n",
    "                             h1,\n",
    "                             linewidth=2,\n",
    "                             edgecolor='white',\n",
    "                             facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "        plt.show()\n",
    "        i = i + 1\n",
    "        if i > 8:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
