{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carmelo/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/carmelo/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/carmelo/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/carmelo/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/carmelo/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/carmelo/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/carmelo/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/carmelo/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/carmelo/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/carmelo/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/carmelo/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/carmelo/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Lambda\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the next frame in the sequence\n",
    "\n",
    "def next_frame(last_row, last_frame, column):\n",
    "    lower = max(0, last_row-1)\n",
    "    upper = min(last_frame.shape[0]-1, last_row+1)\n",
    "    row = np.random.randint(lower, upper+1)\n",
    "    frame = last_frame.copy()\n",
    "    frame[row, column] = 1\n",
    "    return frame, row\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence of frames of a dot moving across an image\n",
    "\n",
    "def build_frames(size):\n",
    "    frames = list()\n",
    "    \n",
    "    # create the first frame\n",
    "    frame = np.zeros((size, size), dtype=np.float32)\n",
    "    row = np.random.randint(0, size)\n",
    "    # decide if we are heading left or right\n",
    "    right = 1 if np.random.rand()<0.5 else 0\n",
    "    col = 0 if right else size-1\n",
    "    frame[row, col] = 1\n",
    "    frames.append(frame)\n",
    "    # cretae all remaining frames\n",
    "    for i in range(1, size):\n",
    "        col = col + 1 if right else col - 1\n",
    "        frame, row = next_frame(row, frame, col)\n",
    "        frames.append(frame)\n",
    "    return frames, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAABLCAYAAABOfV0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAB+ElEQVR4nO3d0YkiQRiF0b+WCcF53s5B84/AzsF5XnOoDWBL6IJxbi91DvhWSHOxP0RobL33AuDn/UpfAMCqBBggRIABQgQYIESAAUIEGCDkY+bw5XLp27a96VLO4fF41PP5bEfPr7BJVdW+78/e++eRszYZW2EX98/Yq8/KVIC3bav7/f59V3VCt9tt6vwKm1RVtda+jp61ydgKu7h/xl59VvwEARAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQMvUkHKS1dvgp16qqWuUfX+zyr3duMvver/gGDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIVOPIu/7PvUI3gqPO85uMuN/3c8mY2fa5Sz38SqbvHpv34ABQgQYIESAAUIEGCBEgAFCBBggRIABQgQYIESAAUIEGCBEgAFCpgJ8vV6r9374tYLZTVbYzyZjZ9rlLJuvvolvwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBAiwAAhAgwQIsAAIQIMENJm/mK5tfanqr7edzmn8Lv3/nn08CKbVE3sYpOxRXaxydhwl6kAA/B9/AQBECLAACECDBAiwAAhAgwQIsAAIQIMECLAACECDBDyF6WZ8PWw/fsVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "size = 5\n",
    "frames, right = build_frames(size)\n",
    "\n",
    "plt.figure()\n",
    "for i in range(size):\n",
    "    plt.subplot(1, size, i+1)\n",
    "    plt.imshow(frames[i], cmap='binary')\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_examples(size, n_patterns):\n",
    "    X, y = list(), list()\n",
    "    for _ in range(n_patterns):\n",
    "        frames, right = build_frames(size)\n",
    "        X.append(frames)\n",
    "        y.append(right)\n",
    "    X = np.array(X).reshape(n_patterns, size, size, size, 1)\n",
    "    y = np.array(y).reshape(n_patterns, 1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [samples, timesteps, width, height, channels]\n",
    "SIZE = 50\n",
    "TIMESTEPS, WIDTH, HEIGHT = SIZE, SIZE, SIZE\n",
    "NPATTERNS = 4096\n",
    "X_train, y_train = generate_examples(SIZE, NPATTERNS)\n",
    "X_test, y_test = generate_examples(SIZE, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeDistributed Way 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/carmelo/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"cnn_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 50, 50, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 49, 49, 2)         10        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 2)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "=================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"lstm_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 50, 50, 50, 1)]   0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 50, 1152)          10        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 50)                240600    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 240,661\n",
      "Trainable params: 240,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/carmelo/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "def build_cnn(inputs):\n",
    "    x = Conv2D(2, (2,2), activation='relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    return Model(inputs=inputs, outputs=x, name='cnn_model')\n",
    "\n",
    "\n",
    "inputs = Input(shape=(WIDTH, HEIGHT, 1))\n",
    "cnn_model = build_cnn(inputs)\n",
    "cnn_model.summary()\n",
    "\n",
    "inputs = Input(shape=(TIMESTEPS, WIDTH, HEIGHT, 1))\n",
    "x = TimeDistributed(cnn_model)(inputs)\n",
    "x = LSTM(50)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=inputs, outputs=x, name='lstm_model')\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3276 samples, validate on 820 samples\n",
      "Epoch 1/128\n",
      "3276/3276 - 11s - loss: 0.2156 - acc: 0.8971 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 2/128\n",
      "3276/3276 - 9s - loss: 0.0877 - acc: 0.9847 - val_loss: 0.0147 - val_acc: 1.0000\n",
      "Epoch 3/128\n",
      "3276/3276 - 9s - loss: 0.0070 - acc: 0.9997 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 4/128\n",
      "3276/3276 - 9s - loss: 0.0015 - acc: 1.0000 - val_loss: 9.9065e-04 - val_acc: 1.0000\n",
      "Epoch 5/128\n",
      "3276/3276 - 9s - loss: 7.3778e-04 - acc: 1.0000 - val_loss: 5.7930e-04 - val_acc: 1.0000\n",
      "Epoch 6/128\n",
      "3276/3276 - 9s - loss: 4.6994e-04 - acc: 1.0000 - val_loss: 3.9839e-04 - val_acc: 1.0000\n",
      "Epoch 7/128\n",
      "3276/3276 - 9s - loss: 3.3904e-04 - acc: 1.0000 - val_loss: 3.0060e-04 - val_acc: 1.0000\n",
      "Epoch 8/128\n",
      "3276/3276 - 9s - loss: 2.6340e-04 - acc: 1.0000 - val_loss: 2.3952e-04 - val_acc: 1.0000\n",
      "Epoch 9/128\n",
      "3276/3276 - 9s - loss: 2.1436e-04 - acc: 1.0000 - val_loss: 1.9876e-04 - val_acc: 1.0000\n",
      "Epoch 10/128\n",
      "3276/3276 - 9s - loss: 1.8022e-04 - acc: 1.0000 - val_loss: 1.6924e-04 - val_acc: 1.0000\n",
      "Epoch 11/128\n",
      "3276/3276 - 9s - loss: 1.5510e-04 - acc: 1.0000 - val_loss: 1.4684e-04 - val_acc: 1.0000\n",
      "Epoch 12/128\n",
      "3276/3276 - 9s - loss: 1.3571e-04 - acc: 1.0000 - val_loss: 1.2933e-04 - val_acc: 1.0000\n",
      "Epoch 13/128\n",
      "3276/3276 - 9s - loss: 1.2022e-04 - acc: 1.0000 - val_loss: 1.1504e-04 - val_acc: 1.0000\n",
      "Epoch 14/128\n",
      "3276/3276 - 9s - loss: 1.0747e-04 - acc: 1.0000 - val_loss: 1.0321e-04 - val_acc: 1.0000\n",
      "Epoch 15/128\n",
      "3276/3276 - 9s - loss: 9.6783e-05 - acc: 1.0000 - val_loss: 9.3179e-05 - val_acc: 1.0000\n",
      "Epoch 16/128\n",
      "3276/3276 - 9s - loss: 8.7711e-05 - acc: 1.0000 - val_loss: 8.4625e-05 - val_acc: 1.0000\n",
      "Epoch 17/128\n",
      "3276/3276 - 9s - loss: 7.9923e-05 - acc: 1.0000 - val_loss: 7.7249e-05 - val_acc: 1.0000\n",
      "Epoch 18/128\n",
      "3276/3276 - 9s - loss: 7.3145e-05 - acc: 1.0000 - val_loss: 7.0811e-05 - val_acc: 1.0000\n",
      "Epoch 19/128\n",
      "3276/3276 - 9s - loss: 6.7196e-05 - acc: 1.0000 - val_loss: 6.5108e-05 - val_acc: 1.0000\n",
      "Epoch 20/128\n",
      "3276/3276 - 9s - loss: 6.1926e-05 - acc: 1.0000 - val_loss: 6.0056e-05 - val_acc: 1.0000\n",
      "Epoch 21/128\n",
      "3276/3276 - 9s - loss: 5.7218e-05 - acc: 1.0000 - val_loss: 5.5553e-05 - val_acc: 1.0000\n",
      "Epoch 22/128\n",
      "3276/3276 - 9s - loss: 5.2977e-05 - acc: 1.0000 - val_loss: 5.1445e-05 - val_acc: 1.0000\n",
      "Epoch 23/128\n",
      "3276/3276 - 9s - loss: 4.9152e-05 - acc: 1.0000 - val_loss: 4.7775e-05 - val_acc: 1.0000\n",
      "Epoch 24/128\n",
      "3276/3276 - 9s - loss: 4.5684e-05 - acc: 1.0000 - val_loss: 4.4411e-05 - val_acc: 1.0000\n",
      "Epoch 25/128\n",
      "3276/3276 - 9s - loss: 4.2527e-05 - acc: 1.0000 - val_loss: 4.1380e-05 - val_acc: 1.0000\n",
      "Epoch 26/128\n",
      "3276/3276 - 9s - loss: 3.9662e-05 - acc: 1.0000 - val_loss: 3.8612e-05 - val_acc: 1.0000\n",
      "Epoch 27/128\n",
      "3276/3276 - 9s - loss: 3.7056e-05 - acc: 1.0000 - val_loss: 3.6095e-05 - val_acc: 1.0000\n",
      "Epoch 28/128\n",
      "3276/3276 - 9s - loss: 3.4682e-05 - acc: 1.0000 - val_loss: 3.3801e-05 - val_acc: 1.0000\n",
      "Epoch 29/128\n",
      "3276/3276 - 9s - loss: 3.2510e-05 - acc: 1.0000 - val_loss: 3.1710e-05 - val_acc: 1.0000\n",
      "Epoch 30/128\n",
      "3276/3276 - 9s - loss: 3.0509e-05 - acc: 1.0000 - val_loss: 2.9748e-05 - val_acc: 1.0000\n",
      "Epoch 31/128\n",
      "3276/3276 - 9s - loss: 2.8645e-05 - acc: 1.0000 - val_loss: 2.7935e-05 - val_acc: 1.0000\n",
      "Epoch 32/128\n",
      "3276/3276 - 9s - loss: 2.6901e-05 - acc: 1.0000 - val_loss: 2.6235e-05 - val_acc: 1.0000\n",
      "Epoch 33/128\n",
      "3276/3276 - 9s - loss: 2.5261e-05 - acc: 1.0000 - val_loss: 2.4622e-05 - val_acc: 1.0000\n",
      "Epoch 34/128\n",
      "3276/3276 - 9s - loss: 2.3711e-05 - acc: 1.0000 - val_loss: 2.3105e-05 - val_acc: 1.0000\n",
      "Epoch 35/128\n",
      "3276/3276 - 9s - loss: 2.2245e-05 - acc: 1.0000 - val_loss: 2.1669e-05 - val_acc: 1.0000\n",
      "Epoch 36/128\n",
      "3276/3276 - 9s - loss: 2.0857e-05 - acc: 1.0000 - val_loss: 2.0303e-05 - val_acc: 1.0000\n",
      "Epoch 37/128\n",
      "3276/3276 - 9s - loss: 1.9549e-05 - acc: 1.0000 - val_loss: 1.9026e-05 - val_acc: 1.0000\n",
      "Epoch 38/128\n",
      "3276/3276 - 9s - loss: 1.8327e-05 - acc: 1.0000 - val_loss: 1.7841e-05 - val_acc: 1.0000\n",
      "Epoch 39/128\n",
      "3276/3276 - 9s - loss: 1.7193e-05 - acc: 1.0000 - val_loss: 1.6742e-05 - val_acc: 1.0000\n",
      "Epoch 40/128\n",
      "3276/3276 - 9s - loss: 1.6147e-05 - acc: 1.0000 - val_loss: 1.5733e-05 - val_acc: 1.0000\n",
      "Epoch 41/128\n",
      "3276/3276 - 9s - loss: 1.5184e-05 - acc: 1.0000 - val_loss: 1.4798e-05 - val_acc: 1.0000\n",
      "Epoch 42/128\n",
      "3276/3276 - 9s - loss: 1.4296e-05 - acc: 1.0000 - val_loss: 1.3939e-05 - val_acc: 1.0000\n",
      "Epoch 43/128\n",
      "3276/3276 - 9s - loss: 1.3473e-05 - acc: 1.0000 - val_loss: 1.3141e-05 - val_acc: 1.0000\n",
      "Epoch 44/128\n",
      "3276/3276 - 9s - loss: 1.2707e-05 - acc: 1.0000 - val_loss: 1.2398e-05 - val_acc: 1.0000\n",
      "Epoch 45/128\n",
      "3276/3276 - 9s - loss: 1.1995e-05 - acc: 1.0000 - val_loss: 1.1707e-05 - val_acc: 1.0000\n",
      "Epoch 46/128\n",
      "3276/3276 - 9s - loss: 1.1335e-05 - acc: 1.0000 - val_loss: 1.1071e-05 - val_acc: 1.0000\n",
      "Epoch 47/128\n",
      "3276/3276 - 9s - loss: 1.0727e-05 - acc: 1.0000 - val_loss: 1.0486e-05 - val_acc: 1.0000\n",
      "Epoch 48/128\n",
      "3276/3276 - 9s - loss: 1.0169e-05 - acc: 1.0000 - val_loss: 9.9463e-06 - val_acc: 1.0000\n",
      "Epoch 49/128\n",
      "3276/3276 - 9s - loss: 9.6525e-06 - acc: 1.0000 - val_loss: 9.4465e-06 - val_acc: 1.0000\n",
      "Epoch 50/128\n",
      "3276/3276 - 9s - loss: 9.1714e-06 - acc: 1.0000 - val_loss: 8.9780e-06 - val_acc: 1.0000\n",
      "Epoch 51/128\n",
      "3276/3276 - 9s - loss: 8.7207e-06 - acc: 1.0000 - val_loss: 8.5422e-06 - val_acc: 1.0000\n",
      "Epoch 52/128\n",
      "3276/3276 - 9s - loss: 8.2961e-06 - acc: 1.0000 - val_loss: 8.1268e-06 - val_acc: 1.0000\n",
      "Epoch 53/128\n",
      "3276/3276 - 9s - loss: 7.8932e-06 - acc: 1.0000 - val_loss: 7.7342e-06 - val_acc: 1.0000\n",
      "Epoch 54/128\n",
      "3276/3276 - 9s - loss: 7.5109e-06 - acc: 1.0000 - val_loss: 7.3599e-06 - val_acc: 1.0000\n",
      "Epoch 55/128\n",
      "3276/3276 - 9s - loss: 7.1468e-06 - acc: 1.0000 - val_loss: 7.0038e-06 - val_acc: 1.0000\n",
      "Epoch 56/128\n",
      "3276/3276 - 9s - loss: 6.8000e-06 - acc: 1.0000 - val_loss: 6.6635e-06 - val_acc: 1.0000\n",
      "Epoch 57/128\n",
      "3276/3276 - 9s - loss: 6.4695e-06 - acc: 1.0000 - val_loss: 6.3390e-06 - val_acc: 1.0000\n",
      "Epoch 58/128\n",
      "3276/3276 - 9s - loss: 6.1534e-06 - acc: 1.0000 - val_loss: 6.0295e-06 - val_acc: 1.0000\n",
      "Epoch 59/128\n",
      "3276/3276 - 9s - loss: 5.8525e-06 - acc: 1.0000 - val_loss: 5.7341e-06 - val_acc: 1.0000\n",
      "Epoch 60/128\n",
      "3276/3276 - 9s - loss: 5.5649e-06 - acc: 1.0000 - val_loss: 5.4517e-06 - val_acc: 1.0000\n",
      "Epoch 61/128\n",
      "3276/3276 - 9s - loss: 5.2912e-06 - acc: 1.0000 - val_loss: 5.1835e-06 - val_acc: 1.0000\n",
      "Epoch 62/128\n",
      "3276/3276 - 9s - loss: 5.0308e-06 - acc: 1.0000 - val_loss: 4.9275e-06 - val_acc: 1.0000\n",
      "Epoch 63/128\n",
      "3276/3276 - 9s - loss: 4.7820e-06 - acc: 1.0000 - val_loss: 4.6844e-06 - val_acc: 1.0000\n",
      "Epoch 64/128\n",
      "3276/3276 - 9s - loss: 4.5454e-06 - acc: 1.0000 - val_loss: 4.4514e-06 - val_acc: 1.0000\n",
      "Epoch 65/128\n",
      "3276/3276 - 9s - loss: 4.3195e-06 - acc: 1.0000 - val_loss: 4.2311e-06 - val_acc: 1.0000\n",
      "Epoch 66/128\n",
      "3276/3276 - 9s - loss: 4.1045e-06 - acc: 1.0000 - val_loss: 4.0194e-06 - val_acc: 1.0000\n",
      "Epoch 67/128\n",
      "3276/3276 - 9s - loss: 3.8994e-06 - acc: 1.0000 - val_loss: 3.8187e-06 - val_acc: 1.0000\n",
      "Epoch 68/128\n",
      "3276/3276 - 9s - loss: 3.7039e-06 - acc: 1.0000 - val_loss: 3.6270e-06 - val_acc: 1.0000\n",
      "Epoch 69/128\n",
      "3276/3276 - 9s - loss: 3.5180e-06 - acc: 1.0000 - val_loss: 3.4452e-06 - val_acc: 1.0000\n",
      "Epoch 70/128\n",
      "3276/3276 - 9s - loss: 3.3420e-06 - acc: 1.0000 - val_loss: 3.2734e-06 - val_acc: 1.0000\n",
      "Epoch 71/128\n",
      "3276/3276 - 9s - loss: 3.1757e-06 - acc: 1.0000 - val_loss: 3.1112e-06 - val_acc: 1.0000\n",
      "Epoch 72/128\n",
      "3276/3276 - 9s - loss: 3.0185e-06 - acc: 1.0000 - val_loss: 2.9576e-06 - val_acc: 1.0000\n",
      "Epoch 73/128\n",
      "3276/3276 - 9s - loss: 2.8698e-06 - acc: 1.0000 - val_loss: 2.8125e-06 - val_acc: 1.0000\n",
      "Epoch 74/128\n",
      "3276/3276 - 9s - loss: 2.7293e-06 - acc: 1.0000 - val_loss: 2.6744e-06 - val_acc: 1.0000\n",
      "Epoch 75/128\n",
      "3276/3276 - 9s - loss: 2.5960e-06 - acc: 1.0000 - val_loss: 2.5441e-06 - val_acc: 1.0000\n",
      "Epoch 76/128\n",
      "3276/3276 - 9s - loss: 2.4693e-06 - acc: 1.0000 - val_loss: 2.4196e-06 - val_acc: 1.0000\n",
      "Epoch 77/128\n",
      "3276/3276 - 9s - loss: 2.3485e-06 - acc: 1.0000 - val_loss: 2.3012e-06 - val_acc: 1.0000\n",
      "Epoch 78/128\n",
      "3276/3276 - 9s - loss: 2.2331e-06 - acc: 1.0000 - val_loss: 2.1881e-06 - val_acc: 1.0000\n",
      "Epoch 79/128\n",
      "3276/3276 - 9s - loss: 2.1231e-06 - acc: 1.0000 - val_loss: 2.0800e-06 - val_acc: 1.0000\n",
      "Epoch 80/128\n",
      "3276/3276 - 9s - loss: 2.0178e-06 - acc: 1.0000 - val_loss: 1.9767e-06 - val_acc: 1.0000\n",
      "Epoch 81/128\n",
      "3276/3276 - 9s - loss: 1.9170e-06 - acc: 1.0000 - val_loss: 1.8776e-06 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/128\n",
      "3276/3276 - 9s - loss: 1.8208e-06 - acc: 1.0000 - val_loss: 1.7829e-06 - val_acc: 1.0000\n",
      "Epoch 83/128\n",
      "3276/3276 - 9s - loss: 1.7282e-06 - acc: 1.0000 - val_loss: 1.6922e-06 - val_acc: 1.0000\n",
      "Epoch 84/128\n",
      "3276/3276 - 9s - loss: 1.6396e-06 - acc: 1.0000 - val_loss: 1.6051e-06 - val_acc: 1.0000\n",
      "Epoch 85/128\n",
      "3276/3276 - 9s - loss: 1.5545e-06 - acc: 1.0000 - val_loss: 1.5213e-06 - val_acc: 1.0000\n",
      "Epoch 86/128\n",
      "3276/3276 - 9s - loss: 1.4727e-06 - acc: 1.0000 - val_loss: 1.4409e-06 - val_acc: 1.0000\n",
      "Epoch 87/128\n",
      "3276/3276 - 9s - loss: 1.3942e-06 - acc: 1.0000 - val_loss: 1.3633e-06 - val_acc: 1.0000\n",
      "Epoch 88/128\n",
      "3276/3276 - 9s - loss: 1.3186e-06 - acc: 1.0000 - val_loss: 1.2892e-06 - val_acc: 1.0000\n",
      "Epoch 89/128\n",
      "3276/3276 - 9s - loss: 1.2461e-06 - acc: 1.0000 - val_loss: 1.2176e-06 - val_acc: 1.0000\n",
      "Epoch 90/128\n",
      "3276/3276 - 9s - loss: 1.1768e-06 - acc: 1.0000 - val_loss: 1.1495e-06 - val_acc: 1.0000\n",
      "Epoch 91/128\n",
      "3276/3276 - 9s - loss: 1.1106e-06 - acc: 1.0000 - val_loss: 1.0847e-06 - val_acc: 1.0000\n",
      "Epoch 92/128\n",
      "3276/3276 - 9s - loss: 1.0478e-06 - acc: 1.0000 - val_loss: 1.0229e-06 - val_acc: 1.0000\n",
      "Epoch 93/128\n",
      "3276/3276 - 9s - loss: 9.8843e-07 - acc: 1.0000 - val_loss: 9.6501e-07 - val_acc: 1.0000\n",
      "Epoch 94/128\n",
      "3276/3276 - 9s - loss: 9.3276e-07 - acc: 1.0000 - val_loss: 9.1102e-07 - val_acc: 1.0000\n",
      "Epoch 95/128\n",
      "3276/3276 - 9s - loss: 8.8070e-07 - acc: 1.0000 - val_loss: 8.6000e-07 - val_acc: 1.0000\n",
      "Epoch 96/128\n",
      "3276/3276 - 9s - loss: 8.3185e-07 - acc: 1.0000 - val_loss: 8.1264e-07 - val_acc: 1.0000\n",
      "Epoch 97/128\n",
      "3276/3276 - 9s - loss: 7.8625e-07 - acc: 1.0000 - val_loss: 7.6823e-07 - val_acc: 1.0000\n",
      "Epoch 98/128\n",
      "3276/3276 - 9s - loss: 7.4360e-07 - acc: 1.0000 - val_loss: 7.2660e-07 - val_acc: 1.0000\n",
      "Epoch 99/128\n",
      "3276/3276 - 9s - loss: 7.0332e-07 - acc: 1.0000 - val_loss: 6.8715e-07 - val_acc: 1.0000\n",
      "Epoch 100/128\n",
      "3276/3276 - 9s - loss: 6.6562e-07 - acc: 1.0000 - val_loss: 6.5058e-07 - val_acc: 1.0000\n",
      "Epoch 101/128\n",
      "3276/3276 - 9s - loss: 6.3038e-07 - acc: 1.0000 - val_loss: 6.1624e-07 - val_acc: 1.0000\n",
      "Epoch 102/128\n",
      "3276/3276 - 9s - loss: 5.9705e-07 - acc: 1.0000 - val_loss: 5.8359e-07 - val_acc: 1.0000\n",
      "Epoch 103/128\n",
      "3276/3276 - 9s - loss: 5.6534e-07 - acc: 1.0000 - val_loss: 5.5245e-07 - val_acc: 1.0000\n",
      "Epoch 104/128\n",
      "3276/3276 - 9s - loss: 5.3549e-07 - acc: 1.0000 - val_loss: 5.2357e-07 - val_acc: 1.0000\n",
      "Epoch 105/128\n",
      "3276/3276 - 9s - loss: 5.0761e-07 - acc: 1.0000 - val_loss: 4.9643e-07 - val_acc: 1.0000\n",
      "Epoch 106/128\n",
      "3276/3276 - 9s - loss: 4.8130e-07 - acc: 1.0000 - val_loss: 4.7062e-07 - val_acc: 1.0000\n",
      "Epoch 107/128\n",
      "3276/3276 - 9s - loss: 4.5626e-07 - acc: 1.0000 - val_loss: 4.4615e-07 - val_acc: 1.0000\n",
      "Epoch 108/128\n",
      "3276/3276 - 9s - loss: 4.3264e-07 - acc: 1.0000 - val_loss: 4.2306e-07 - val_acc: 1.0000\n",
      "Epoch 109/128\n",
      "3276/3276 - 9s - loss: 4.1059e-07 - acc: 1.0000 - val_loss: 4.0193e-07 - val_acc: 1.0000\n",
      "Epoch 110/128\n",
      "3276/3276 - 9s - loss: 3.9039e-07 - acc: 1.0000 - val_loss: 3.8245e-07 - val_acc: 1.0000\n",
      "Epoch 111/128\n",
      "3276/3276 - 9s - loss: 3.7159e-07 - acc: 1.0000 - val_loss: 3.6409e-07 - val_acc: 1.0000\n",
      "Epoch 112/128\n",
      "3276/3276 - 9s - loss: 3.5377e-07 - acc: 1.0000 - val_loss: 3.4654e-07 - val_acc: 1.0000\n",
      "Epoch 113/128\n",
      "3276/3276 - 9s - loss: 3.3674e-07 - acc: 1.0000 - val_loss: 3.2987e-07 - val_acc: 1.0000\n",
      "Epoch 114/128\n",
      "3276/3276 - 9s - loss: 3.2048e-07 - acc: 1.0000 - val_loss: 3.1397e-07 - val_acc: 1.0000\n",
      "Epoch 115/128\n",
      "3276/3276 - 9s - loss: 3.0495e-07 - acc: 1.0000 - val_loss: 2.9873e-07 - val_acc: 1.0000\n",
      "Epoch 116/128\n",
      "3276/3276 - 9s - loss: 2.9031e-07 - acc: 1.0000 - val_loss: 2.8473e-07 - val_acc: 1.0000\n",
      "Epoch 117/128\n",
      "3276/3276 - 9s - loss: 2.7697e-07 - acc: 1.0000 - val_loss: 2.7183e-07 - val_acc: 1.0000\n",
      "Epoch 118/128\n",
      "3276/3276 - 9s - loss: 2.6452e-07 - acc: 1.0000 - val_loss: 2.5960e-07 - val_acc: 1.0000\n",
      "Epoch 119/128\n",
      "3276/3276 - 9s - loss: 2.5257e-07 - acc: 1.0000 - val_loss: 2.4782e-07 - val_acc: 1.0000\n",
      "Epoch 120/128\n",
      "3276/3276 - 9s - loss: 2.4105e-07 - acc: 1.0000 - val_loss: 2.3644e-07 - val_acc: 1.0000\n",
      "Epoch 121/128\n",
      "3276/3276 - 9s - loss: 2.2993e-07 - acc: 1.0000 - val_loss: 2.2544e-07 - val_acc: 1.0000\n",
      "Epoch 122/128\n",
      "3276/3276 - 9s - loss: 2.1920e-07 - acc: 1.0000 - val_loss: 2.1487e-07 - val_acc: 1.0000\n",
      "Epoch 123/128\n",
      "3276/3276 - 9s - loss: 2.0883e-07 - acc: 1.0000 - val_loss: 2.0459e-07 - val_acc: 1.0000\n",
      "Epoch 124/128\n",
      "3276/3276 - 9s - loss: 1.9879e-07 - acc: 1.0000 - val_loss: 1.9475e-07 - val_acc: 1.0000\n",
      "Epoch 125/128\n",
      "3276/3276 - 9s - loss: 1.8912e-07 - acc: 1.0000 - val_loss: 1.8518e-07 - val_acc: 1.0000\n",
      "Epoch 126/128\n",
      "3276/3276 - 9s - loss: 1.7987e-07 - acc: 1.0000 - val_loss: 1.7624e-07 - val_acc: 1.0000\n",
      "Epoch 127/128\n",
      "3276/3276 - 9s - loss: 1.7154e-07 - acc: 1.0000 - val_loss: 1.6846e-07 - val_acc: 1.0000\n",
      "Epoch 128/128\n",
      "3276/3276 - 9s - loss: 1.6402e-07 - acc: 1.0000 - val_loss: 1.6109e-07 - val_acc: 1.0000\n",
      "loss 0.000000, acc 100.000000\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=128, validation_split=0.2,\n",
    "                    callbacks= [ EarlyStopping(monitor='val_loss', patience=16)], verbose=2)\n",
    "\n",
    "loss, acc =  model.evaluate(X_test, y_test, verbose=0)\n",
    "print('loss %f, acc %f' % (loss, acc*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeDistributed Way 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "cnn_model.add(Input(shape=(WIDTH, HEIGHT, 1)))\n",
    "\n",
    "cnn_model.add(Conv2D(2, (2,2), activation='relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "cnn_model.summary()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(cnn_model, input_shape=(None, WIDTH, HEIGHT, 1)))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=128, validation_split=0.2,\n",
    "                    callbacks= [ EarlyStopping(monitor='val_loss', patience=16)], verbose=2)\n",
    "\n",
    "loss, acc =  model.evaluate(X_test, y_test, verbose=0)\n",
    "print('loss %f, acc %f' % (loss, acc*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeDistributed Way 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv2D(2, (2,2), activation='relu'), input_shape=(None, WIDTH, HEIGHT, 1)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2))))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=128, validation_split=0.2,\n",
    "                    callbacks= [ EarlyStopping(monitor='val_loss', patience=16)], verbose=2)\n",
    "\n",
    "loss, acc =  model.evaluate(X_test, y_test, verbose=0)\n",
    "print('loss %f, acc %f' % (loss, acc*100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
